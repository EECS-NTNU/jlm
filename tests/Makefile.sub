TESTS = \

include tests/util/Makefile.sub
include tests/libjlm/Makefile.sub
include tests/libjlc/Makefile.sub

TEST_SOURCES = \
	tests/test-operation.cpp \
	tests/test-registry.cpp \
	tests/test-runner.cpp \
	tests/test-types.cpp \
	$(patsubst %, tests/%.cpp, $(TESTS))

tests/test-runner: libjlc.a libjlm.a
tests/test-runner: CPPFLAGS += -Ilibjlm/include -Ilibjlc/include
tests/test-runner: LDFLAGS=-L. -Lexternal/jive -ljlc -ljlm $(shell $(LLVMCONFIG) --ldflags --libs) -ljive
tests/test-runner: %: $(patsubst %.cpp, %.la, $(TEST_SOURCES)) libjlm.a
	$(CXX) -o $@ $(filter %.la, $^) $(LDFLAGS)

$(patsubst %, tests/%.la, $(TESTS)): CPPFLAGS += -Itests

TESTLOG = true

check: check-utests check-ctests

check-ctests: jlc jlm-opt
	rm -rf ctests.log
	@FAILED_TESTS="" ; \
	for TEST in `ls tests/c-tests`; do \
		$(TESTLOG) -n "$$TEST: " ; if tests/test-jlc.sh tests/c-tests/$$TEST >>ctests.log 2>&1 ; then $(TESTLOG) pass ; else $(TESTLOG) FAIL ; FAILED_TESTS="$$FAILED_TESTS $$TEST" ; fi ; \
	done ; \
	if [ "x$$FAILED_TESTS" != x ] ; then echo "Failed tests:$$FAILED_TESTS" ; else echo "All tests passed" ; fi ; \

check-utests: tests/test-runner
	rm -rf utests.log
	@FAILED_TESTS="" ; \
	for TEST in $(TESTS); do \
		$(TESTLOG) -n "$$TEST: " ; if tests/test-runner $$TEST >>utests.log 2>&1 ; then $(TESTLOG) pass ; else $(TESTLOG) FAIL ; FAILED_TESTS="$$FAILED_TESTS $$TEST" ; fi ; \
	done ; \
	if [ "x$$FAILED_TESTS" != x ] ; then echo "Failed tests:$$FAILED_TESTS" ; else echo "All tests passed" ; fi ; \

valgrind-check: tests/test-runner
	rm -rf check.log
	@FAILED_TESTS="" ; \
	for TEST in $(TESTS); do \
		$(TESTLOG) -n "$$TEST: " ; if valgrind --leak-check=full --error-exitcode=1 tests/test-runner $$TEST >>check.log 2>&1 ; then $(TESTLOG) pass ; else $(TESTLOG) FAIL ; FAILED_TESTS="$$UNEXPECTED_FAILED_TESTS $$TEST" ; fi ; \
	done ; \
	if [ "x$$FAILED_TESTS" != x ] ; then echo "Failed tests:$$FAILED_TESTS" ; else echo "All tests passed" ; fi ; \
